`# ğŸ§ª API Test Automation Framework

A professional API testing framework built using **Python**, **Pytest**, and **Allure** for reporting.  
This framework is designed to test RESTful APIs using data-driven and contract-based testing approaches.  
Target API: [ReqRes Public API](https://reqres.in/)

---

## âœ… Features

- Modular and scalable folder structure
- Configurable environments (e.g. dev, staging)
- JSON Schema validation (contract testing)
- Data-driven POST testing
- Boundary and negative test cases
- Retry logic and timeouts
- Allure report integration
- Pytest markers and logging
- Compatible with CI/CD (via GitHub Actions)

---

## ğŸ—‚ï¸ Project Structure

```
api_test_framework/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ large_payload.json
â”‚   â””â”€â”€ post_user_payloads.json
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ create_user_schema.json
â”‚   â”œâ”€â”€ single_user_schema.json
â”‚   â””â”€â”€ user_list_schema.json
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_user_retrieval.py      # GET operations & user listing
â”‚   â”œâ”€â”€ test_user_creation.py       # POST operations & user creation
â”‚   â”œâ”€â”€ test_error_scenarios.py     # 404, invalid requests, edge cases
â”‚   â”œâ”€â”€ test_api_validation.py      # Schema validation & headers
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ api_utils.py
â”œâ”€â”€ logs/
â”œâ”€â”€ reports/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini                     # Test configuration & markers
â”œâ”€â”€ test_runner.sh                 # Test execution script
â”œâ”€â”€ setup.sh                      # Automated setup script
â”œâ”€â”€ README.md
â”œâ”€â”€ troubleshooting_log.md
â””â”€â”€ conftest.py
```

ğŸ“¸ *Screenshot of project structure:*  
![Project_Structure](images/project_structure.jpg)


---

## âš™ï¸ Installation & Setup

### Quick Setup (Recommended)
```bash
# Clone this repo
git clone https://github.com/YOUR-USERNAME/api_test_automation_framework.git
cd api_test_automation_framework

# Run the setup script (creates venv and installs dependencies)
./setup.sh
```

### Manual Setup
```bash
# Clone this repo
git clone https://github.com/YOUR-USERNAME/api_test_automation_framework.git
cd api_test_automation_framework

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

ğŸ“¸ Chrome installation step (Linux):
![Chrome Installed](images/2_chrome_install.jpg)


---

---

## ğŸ§ª Running Tests

### Quick Start
```bash
# Run all tests
./test_runner.sh all

# Run smoke tests (quick validation)
./test_runner.sh smoke

# Run specific test categories
./test_runner.sh regression
./test_runner.sh negative
```

### Test Categories Available

| Category | Description | Command |
|----------|-------------|---------|
| ğŸš€ **smoke** | Core functionality validation | `./test_runner.sh smoke` |
| ğŸ”„ **regression** | Comprehensive testing | `./test_runner.sh regression` |
| âŒ **negative** | Error scenarios & edge cases | `./test_runner.sh negative` |
| ğŸ” **boundary** | Boundary testing (large payloads) | `./test_runner.sh boundary` |
| ğŸ“‹ **contract** | API schema validation | `./test_runner.sh contract` |
| âš¡ **performance** | Response time validation | `./test_runner.sh performance` |
| ï¿½ **retrieval** | User GET operations | `./test_runner.sh retrieval` |
| â• **creation** | User POST operations | `./test_runner.sh creation` |

### Direct pytest Commands
```bash
# Run specific test file
pytest tests/test_user_retrieval.py -v

# Run tests with specific markers
pytest -m "smoke" -v
pytest -m "user_creation and not boundary" -v

# Run all tests with detailed output
pytest -v --tb=short
```


---

---

## ğŸ“Š Generate Allure Report

```bash
# Generate and view HTML report
allure generate reports/allure-results -o reports/html --clean
allure open reports/html

# Or serve live report
allure serve reports/allure-results
```

---

## ğŸš¦ Test Organization

### Test Modules

| Module | Purpose | Key Features |
|--------|---------|--------------|
| `test_user_retrieval.py` | GET operations | User listing, single user, pagination |
| `test_user_creation.py` | POST operations | Data-driven creation, boundary testing |
| `test_error_scenarios.py` | Error handling | 404s, invalid data, malformed requests |
| `test_api_validation.py` | Contract testing | Schema validation, headers, performance |

### Pytest Markers

The framework uses comprehensive pytest markers for test categorization:

```bash
# Execution-based markers
@pytest.mark.smoke          # Quick validation tests
@pytest.mark.regression      # Comprehensive test suite
@pytest.mark.negative        # Error scenario tests
@pytest.mark.boundary        # Edge case and boundary tests

# Feature-based markers  
@pytest.mark.user_retrieval  # GET user operations
@pytest.mark.user_creation   # POST user operations
@pytest.mark.error_scenarios # Error handling tests
@pytest.mark.api_validation  # Contract and validation tests

# Quality markers
@pytest.mark.contract        # API schema validation
@pytest.mark.performance     # Response time validation
```

### Running Specific Test Categories
```bash
# Run only smoke tests
pytest -m smoke

# Run user creation tests
pytest -m user_creation

# Combine markers
pytest -m "smoke and user_retrieval"

# Exclude certain tests
pytest -m "not boundary"
```


---

ğŸ›  Troubleshooting

See troubleshooting_log.md for common errors and fixes (e.g., Chrome driver, Allure, virtualenv).


---

ğŸ¤ Contributing

Pull requests are welcome. Please open an issue first to discuss changes.


---

ğŸ“„ License

This project is licensed under the MIT License.
